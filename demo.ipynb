{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in Google Colab\n"
     ]
    }
   ],
   "source": [
    "# additional google colab setup\n",
    "import sys\n",
    "\n",
    "\n",
    "def colab_install():\n",
    "    import torch\n",
    "    if not torch.cuda.is_available():\n",
    "      print(\"CUDA is not available. \\nPick a GPU before running this notebook. \\nGo to 'Runtime' -> 'Change runtime type' to do this.\")\n",
    "      return \n",
    "    %pip install transformers\n",
    "    %pip install datasets\n",
    "    %pip install peft\n",
    "    %pip install bitsandbytes\n",
    "    return\n",
    "\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Running in Google Colab\")\n",
    "    # Install required packages\n",
    "    colab_install()\n",
    "else:\n",
    "    print(\"Not running in Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, TaskType, prepare_model_for_kbit_training, get_peft_model\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "transformers.set_seed(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/survai-finetuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/survai-finetuning/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# TODO remove\n",
    "DEBUG = True\n",
    "if DEBUG:\n",
    "    %cd survai-finetuning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  149k  100  149k    0     0   439k      0 --:--:-- --:--:-- --:--:--  439k\n"
     ]
    }
   ],
   "source": [
    "# download dataset\n",
    "!curl -L -o 2016_anes_argyle.pkl https://github.com/tobihol/survai-finetuning/raw/main/2016_anes_argyle.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>discuss_politics</th>\n",
       "      <th>ideology</th>\n",
       "      <th>party</th>\n",
       "      <th>church_goer</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>political_interest</th>\n",
       "      <th>patriotism</th>\n",
       "      <th>state</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>white</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a strong Republican</td>\n",
       "      <td>attend church</td>\n",
       "      <td>29</td>\n",
       "      <td>man</td>\n",
       "      <td>somewhat</td>\n",
       "      <td>extremely good</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>Yes</td>\n",
       "      <td>slightly conservative</td>\n",
       "      <td>a weak Republican</td>\n",
       "      <td>do not attend church</td>\n",
       "      <td>26</td>\n",
       "      <td>man</td>\n",
       "      <td>very</td>\n",
       "      <td>extremely good</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>an independent who leans Democratic</td>\n",
       "      <td>do not attend church</td>\n",
       "      <td>23</td>\n",
       "      <td>man</td>\n",
       "      <td>not very</td>\n",
       "      <td>moderately good</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Non-voter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>an independent who leans Republican</td>\n",
       "      <td>attend church</td>\n",
       "      <td>58</td>\n",
       "      <td>man</td>\n",
       "      <td>somewhat</td>\n",
       "      <td>extremely good</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>white</td>\n",
       "      <td>No</td>\n",
       "      <td>moderate</td>\n",
       "      <td>an independent who leans Democratic</td>\n",
       "      <td>attend church</td>\n",
       "      <td>38</td>\n",
       "      <td>woman</td>\n",
       "      <td>not very</td>\n",
       "      <td>extremely good</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Non-voter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>white</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a strong democrat</td>\n",
       "      <td>attend church</td>\n",
       "      <td>37</td>\n",
       "      <td>woman</td>\n",
       "      <td>not very</td>\n",
       "      <td>extremely good</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>white</td>\n",
       "      <td>Yes</td>\n",
       "      <td>moderate</td>\n",
       "      <td>a strong democrat</td>\n",
       "      <td>attend church</td>\n",
       "      <td>82</td>\n",
       "      <td>man</td>\n",
       "      <td>somewhat</td>\n",
       "      <td>extremely good</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>white</td>\n",
       "      <td>No</td>\n",
       "      <td>moderate</td>\n",
       "      <td>a weak Democrat</td>\n",
       "      <td>attend church</td>\n",
       "      <td>27</td>\n",
       "      <td>man</td>\n",
       "      <td>not very</td>\n",
       "      <td>a little good</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Non-voter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>conservative</td>\n",
       "      <td>a strong democrat</td>\n",
       "      <td>attend church</td>\n",
       "      <td>39</td>\n",
       "      <td>woman</td>\n",
       "      <td>somewhat</td>\n",
       "      <td>neither good nor bad</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>white</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a weak Republican</td>\n",
       "      <td>attend church</td>\n",
       "      <td>52</td>\n",
       "      <td>man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>Non-voter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4270 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       race discuss_politics               ideology  \\\n",
       "0     white              Yes                    NaN   \n",
       "1     white              Yes  slightly conservative   \n",
       "2     white               No                    NaN   \n",
       "3     white              Yes                    NaN   \n",
       "4     white               No               moderate   \n",
       "...     ...              ...                    ...   \n",
       "4265  white              Yes                    NaN   \n",
       "4266  white              Yes               moderate   \n",
       "4267  white               No               moderate   \n",
       "4268  black              Yes           conservative   \n",
       "4269  white              NaN                    NaN   \n",
       "\n",
       "                                    party           church_goer  age gender  \\\n",
       "0                     a strong Republican         attend church   29    man   \n",
       "1                       a weak Republican  do not attend church   26    man   \n",
       "2     an independent who leans Democratic  do not attend church   23    man   \n",
       "3     an independent who leans Republican         attend church   58    man   \n",
       "4     an independent who leans Democratic         attend church   38  woman   \n",
       "...                                   ...                   ...  ...    ...   \n",
       "4265                    a strong democrat         attend church   37  woman   \n",
       "4266                    a strong democrat         attend church   82    man   \n",
       "4267                      a weak Democrat         attend church   27    man   \n",
       "4268                    a strong democrat         attend church   39  woman   \n",
       "4269                    a weak Republican         attend church   52    man   \n",
       "\n",
       "     political_interest            patriotism           state ground_truth  \n",
       "0              somewhat        extremely good       Louisiana        Trump  \n",
       "1                  very        extremely good        Arkansas        Trump  \n",
       "2              not very       moderately good     Mississippi    Non-voter  \n",
       "3              somewhat        extremely good       Tennessee        Trump  \n",
       "4              not very        extremely good            Ohio    Non-voter  \n",
       "...                 ...                   ...             ...          ...  \n",
       "4265           not very        extremely good        Virginia      Clinton  \n",
       "4266           somewhat        extremely good        Virginia        Trump  \n",
       "4267           not very         a little good         Georgia    Non-voter  \n",
       "4268           somewhat  neither good nor bad  North Carolina      Clinton  \n",
       "4269                NaN                   NaN        Missouri    Non-voter  \n",
       "\n",
       "[4270 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_survey = pd.read_pickle(\"2016_anes_argyle.pkl\")\n",
    "df_survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4270 entries, 0 to 4269\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   race                4060 non-null   object\n",
      " 1   discuss_politics    3645 non-null   object\n",
      " 2   ideology            3303 non-null   object\n",
      " 3   party               4247 non-null   object\n",
      " 4   church_goer         4251 non-null   object\n",
      " 5   age                 4149 non-null   UInt8 \n",
      " 6   gender              4218 non-null   object\n",
      " 7   political_interest  3638 non-null   object\n",
      " 8   patriotism          3645 non-null   object\n",
      " 9   state               4242 non-null   object\n",
      " 10  ground_truth        4270 non-null   object\n",
      "dtypes: UInt8(1), object(10)\n",
      "memory usage: 375.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# descriptive statistics\n",
    "df_survey.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"race\",\n",
    "    \"discuss_politics\",\n",
    "    \"ideology\",\n",
    "    \"party\",\n",
    "    \"church_goer\",\n",
    "    \"age\",\n",
    "    \"gender\",\n",
    "    \"political_interest\",\n",
    "    \"patriotism\",\n",
    "    \"state\",\n",
    "]\n",
    "label = \"ground_truth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>discuss_politics</th>\n",
       "      <th>ideology</th>\n",
       "      <th>party</th>\n",
       "      <th>church_goer</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>political_interest</th>\n",
       "      <th>patriotism</th>\n",
       "      <th>state</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>white</td>\n",
       "      <td>Yes</td>\n",
       "      <td>missing</td>\n",
       "      <td>a strong Republican</td>\n",
       "      <td>attend church</td>\n",
       "      <td>29</td>\n",
       "      <td>man</td>\n",
       "      <td>somewhat</td>\n",
       "      <td>extremely good</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>Yes</td>\n",
       "      <td>slightly conservative</td>\n",
       "      <td>a weak Republican</td>\n",
       "      <td>do not attend church</td>\n",
       "      <td>26</td>\n",
       "      <td>man</td>\n",
       "      <td>very</td>\n",
       "      <td>extremely good</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white</td>\n",
       "      <td>No</td>\n",
       "      <td>missing</td>\n",
       "      <td>an independent who leans Democratic</td>\n",
       "      <td>do not attend church</td>\n",
       "      <td>23</td>\n",
       "      <td>man</td>\n",
       "      <td>not very</td>\n",
       "      <td>moderately good</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Non-voter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>Yes</td>\n",
       "      <td>missing</td>\n",
       "      <td>an independent who leans Republican</td>\n",
       "      <td>attend church</td>\n",
       "      <td>58</td>\n",
       "      <td>man</td>\n",
       "      <td>somewhat</td>\n",
       "      <td>extremely good</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>white</td>\n",
       "      <td>No</td>\n",
       "      <td>moderate</td>\n",
       "      <td>an independent who leans Democratic</td>\n",
       "      <td>attend church</td>\n",
       "      <td>38</td>\n",
       "      <td>woman</td>\n",
       "      <td>not very</td>\n",
       "      <td>extremely good</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Non-voter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>white</td>\n",
       "      <td>Yes</td>\n",
       "      <td>missing</td>\n",
       "      <td>a strong democrat</td>\n",
       "      <td>attend church</td>\n",
       "      <td>37</td>\n",
       "      <td>woman</td>\n",
       "      <td>not very</td>\n",
       "      <td>extremely good</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>white</td>\n",
       "      <td>Yes</td>\n",
       "      <td>moderate</td>\n",
       "      <td>a strong democrat</td>\n",
       "      <td>attend church</td>\n",
       "      <td>82</td>\n",
       "      <td>man</td>\n",
       "      <td>somewhat</td>\n",
       "      <td>extremely good</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>white</td>\n",
       "      <td>No</td>\n",
       "      <td>moderate</td>\n",
       "      <td>a weak Democrat</td>\n",
       "      <td>attend church</td>\n",
       "      <td>27</td>\n",
       "      <td>man</td>\n",
       "      <td>not very</td>\n",
       "      <td>a little good</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Non-voter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>black</td>\n",
       "      <td>Yes</td>\n",
       "      <td>conservative</td>\n",
       "      <td>a strong democrat</td>\n",
       "      <td>attend church</td>\n",
       "      <td>39</td>\n",
       "      <td>woman</td>\n",
       "      <td>somewhat</td>\n",
       "      <td>neither good nor bad</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>white</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>a weak Republican</td>\n",
       "      <td>attend church</td>\n",
       "      <td>52</td>\n",
       "      <td>man</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>Non-voter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4270 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       race discuss_politics               ideology  \\\n",
       "0     white              Yes                missing   \n",
       "1     white              Yes  slightly conservative   \n",
       "2     white               No                missing   \n",
       "3     white              Yes                missing   \n",
       "4     white               No               moderate   \n",
       "...     ...              ...                    ...   \n",
       "4265  white              Yes                missing   \n",
       "4266  white              Yes               moderate   \n",
       "4267  white               No               moderate   \n",
       "4268  black              Yes           conservative   \n",
       "4269  white          missing                missing   \n",
       "\n",
       "                                    party           church_goer age gender  \\\n",
       "0                     a strong Republican         attend church  29    man   \n",
       "1                       a weak Republican  do not attend church  26    man   \n",
       "2     an independent who leans Democratic  do not attend church  23    man   \n",
       "3     an independent who leans Republican         attend church  58    man   \n",
       "4     an independent who leans Democratic         attend church  38  woman   \n",
       "...                                   ...                   ...  ..    ...   \n",
       "4265                    a strong democrat         attend church  37  woman   \n",
       "4266                    a strong democrat         attend church  82    man   \n",
       "4267                      a weak Democrat         attend church  27    man   \n",
       "4268                    a strong democrat         attend church  39  woman   \n",
       "4269                    a weak Republican         attend church  52    man   \n",
       "\n",
       "     political_interest            patriotism           state ground_truth  \n",
       "0              somewhat        extremely good       Louisiana        Trump  \n",
       "1                  very        extremely good        Arkansas        Trump  \n",
       "2              not very       moderately good     Mississippi    Non-voter  \n",
       "3              somewhat        extremely good       Tennessee        Trump  \n",
       "4              not very        extremely good            Ohio    Non-voter  \n",
       "...                 ...                   ...             ...          ...  \n",
       "4265           not very        extremely good        Virginia      Clinton  \n",
       "4266           somewhat        extremely good        Virginia        Trump  \n",
       "4267           not very         a little good         Georgia    Non-voter  \n",
       "4268           somewhat  neither good nor bad  North Carolina      Clinton  \n",
       "4269            missing               missing        Missouri    Non-voter  \n",
       "\n",
       "[4270 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we tread missing values as a category \n",
    "df_survey_processed = (\n",
    "    df_survey\n",
    "    .astype({\"age\": str})\n",
    "    .fillna(\"missing\")\n",
    ")\n",
    "df_survey_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please perform a classification task. Given the 2016 survey answers from the American National Election Studies, return which candiate the person voted for. Return a label from ['Trump', 'Clinton', 'Non-voter'] only without any other text.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instruction = (\n",
    "    \"Please perform a classification task. \"\n",
    "    + \"Given the 2016 survey answers from the American National Election Studies, \"\n",
    "    + \"return which candiate the person voted for. \"\n",
    "    + \"Return a label from ['Trump', 'Clinton', 'Non-voter'] only without any other text.\\n\"\n",
    ")\n",
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please perform a classification task. Given th...</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please perform a classification task. Given th...</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please perform a classification task. Given th...</td>\n",
       "      <td>Non-voter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Please perform a classification task. Given th...</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please perform a classification task. Given th...</td>\n",
       "      <td>Non-voter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>Please perform a classification task. Given th...</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>Please perform a classification task. Given th...</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>Please perform a classification task. Given th...</td>\n",
       "      <td>Non-voter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>Please perform a classification task. Given th...</td>\n",
       "      <td>Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>Please perform a classification task. Given th...</td>\n",
       "      <td>Non-voter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4270 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text      label\n",
       "0     Please perform a classification task. Given th...      Trump\n",
       "1     Please perform a classification task. Given th...      Trump\n",
       "2     Please perform a classification task. Given th...  Non-voter\n",
       "3     Please perform a classification task. Given th...      Trump\n",
       "4     Please perform a classification task. Given th...  Non-voter\n",
       "...                                                 ...        ...\n",
       "4265  Please perform a classification task. Given th...    Clinton\n",
       "4266  Please perform a classification task. Given th...      Trump\n",
       "4267  Please perform a classification task. Given th...  Non-voter\n",
       "4268  Please perform a classification task. Given th...    Clinton\n",
       "4269  Please perform a classification task. Given th...  Non-voter\n",
       "\n",
       "[4270 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_name_map = {\n",
    "    \"race\": \"Race\",\n",
    "    \"discuss_politics\": \"Discusses politics\",\n",
    "    \"ideology\": \"Ideology\",\n",
    "    \"party\": \"Party\",\n",
    "    \"church_goer\": \"Church\",\n",
    "    \"age\": \"Age\",\n",
    "    \"gender\": \"Gender\",\n",
    "    \"political_interest\": \"Political interest\",\n",
    "    \"patriotism\": \"American Flag\",\n",
    "    \"state\": \"State\",\n",
    "    \"ground_truth\": \"Vote\",\n",
    "}\n",
    "\n",
    "def create_prompt(row):\n",
    "    prompt = instruction\n",
    "    prompt += \"\\n\".join([f\"{column_name_map[k]}: {v}\" for k, v in row.items()])\n",
    "    return prompt\n",
    "\n",
    "text_series = df_survey_processed[features].apply(create_prompt, axis=\"columns\")\n",
    "label_series = df_survey_processed[label]\n",
    "\n",
    "df_prompts = pd.DataFrame({\"text\": text_series, \"label\": label_series})\n",
    "df_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please perform a classification task. Given the 2016 survey answers from the American National Election Studies, return which candiate the person voted for. Return a label from ['Trump', 'Clinton', 'Non-voter'] only without any other text.\n",
      "Race: white\n",
      "Discusses politics: Yes\n",
      "Ideology: missing\n",
      "Party: a strong Republican\n",
      "Church: attend church\n",
      "Age: 29\n",
      "Gender: man\n",
      "Political interest: somewhat\n",
      "American Flag: extremely good\n",
      "State: Louisiana\n"
     ]
    }
   ],
   "source": [
    "print(df_prompts.text.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump\n"
     ]
    }
   ],
   "source": [
    "print(df_prompts.label.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['race', 'discuss_politics', 'ideology', 'party', 'church_goer', 'age', 'gender', 'political_interest', 'patriotism', 'state', 'ground_truth'],\n",
       "        num_rows: 3416\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['race', 'discuss_politics', 'ideology', 'party', 'church_goer', 'age', 'gender', 'political_interest', 'patriotism', 'state', 'ground_truth'],\n",
       "        num_rows: 854\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_survey_processed, test_size=0.2, random_state=24)\n",
    "dataset_cls = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train, preserve_index=False),\n",
    "    \"test\": Dataset.from_pandas(df_test, preserve_index=False),\n",
    "})\n",
    "dataset_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3416\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 854\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df_prompts, test_size=0.2, random_state=24)\n",
    "dataset_llm = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train, preserve_index=False),\n",
    "    \"test\": Dataset.from_pandas(df_test, preserve_index=False),\n",
    "})\n",
    "dataset_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model selection:\n",
    "- https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard\n",
    "- https://lmarena.ai/\n",
    "- https://crfm.stanford.edu/helm/\n",
    "    - Imputation Benchmark: https://crfm.stanford.edu/helm/classic/latest/#/groups/entity_data_imputation\n",
    "\n",
    "Reproducibility:\n",
    "- (TODO how model revisions)\n",
    "- LLM training/inference in the wild west: the are a ton of differnt libraries/wrappers where each one can implement different changes your evaluations results. (TODO add tokenisation problem that I had during my thesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"EleutherAI/pythia-70m\"\n",
    "model_id = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "# TODO add revision number\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    padding_side=\"left\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "# dataset = dataset.map(\n",
    "#     lambda x: tokenizer(x[\"text\"], truncation=True, padding=\"max_length\"), batched=True\n",
    "# )\n",
    "\n",
    "# dataset = dataset.remove_columns([\"text\", \"label\"])\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae163339c4d4be7bc4551d2f1db5718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3416 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88c8045544b4171bc3c31847e8ee09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/854 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 3416\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 854\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def instruct_tokenize_function(examples):\n",
    "    prompt = [\n",
    "        {\"role\": \"user\", \"content\": examples[\"text\"]},\n",
    "    ]\n",
    "    prompt.append(\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": examples[\"label\"],\n",
    "        }\n",
    "    )\n",
    "    inputs_ids = tokenizer.apply_chat_template(\n",
    "        prompt,\n",
    "        add_generation_prompt=False,\n",
    "    )\n",
    "    attention_mask = np.ones_like(inputs_ids)\n",
    "    return {\n",
    "        \"input_ids\": inputs_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "    }\n",
    "\n",
    "\n",
    "def basic_tokenize_function(examples):\n",
    "    prompt = f\"{examples['text']} \\nVote: {examples['label']} {tokenizer.eos_token}\"\n",
    "    return tokenizer(prompt)\n",
    "\n",
    "\n",
    "tokenized_dataset_llm = dataset_llm.map(basic_tokenize_function).remove_columns(\n",
    "    [\"text\", \"label\"]\n",
    ")\n",
    "tokenized_dataset_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "if getattr(model.config, \"pad_token_id\") is None:\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,636,096 || all params: 1,241,450,496 || trainable%: 0.4540\n"
     ]
    }
   ],
   "source": [
    "lora_rank = 8\n",
    "lora_alpha = 8\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=lora_rank,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=\"all-linear\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def instruct_tokenization(\n",
    "    data: DatasetDict,\n",
    "    tokenizer: AutoTokenizer,\n",
    ") -> Tuple[DatasetDict, Dataset]:\n",
    "    def tokenize_function(examples, is_inference=False):\n",
    "        prompt = [\n",
    "            {\"role\": \"user\", \"content\": examples[\"text\"]},\n",
    "        ]\n",
    "        if not is_inference:\n",
    "            prompt.append(\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": examples[\"label\"],\n",
    "                }\n",
    "            )\n",
    "        inputs_ids = tokenizer.apply_chat_template(\n",
    "            prompt,\n",
    "            add_generation_prompt=is_inference,\n",
    "        )\n",
    "        attention_mask = np.ones_like(inputs_ids)\n",
    "        return {\n",
    "            \"input_ids\": inputs_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "        }\n",
    "\n",
    "    column_names = list(data.column_names.values())[0]\n",
    "    training_data = data.map(tokenize_function, remove_columns=column_names)\n",
    "    from functools import partial\n",
    "\n",
    "    inference_data = data.map(\n",
    "        partial(tokenize_function, is_inference=True), remove_columns=column_names\n",
    "    )\n",
    "\n",
    "    answer_tokens = list(\n",
    "        {\n",
    "            training_ids[len(inference_ids)]\n",
    "            for inference_ids, training_ids in zip(\n",
    "                inference_data[\"train\"][\"input_ids\"]\n",
    "                + inference_data[\"test\"][\"input_ids\"],\n",
    "                training_data[\"train\"][\"input_ids\"]\n",
    "                + training_data[\"test\"][\"input_ids\"],\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    assert len(answer_tokens) == len(\n",
    "        set(data[\"test\"][\"label\"] + data[\"train\"][\"label\"])\n",
    "    )\n",
    "\n",
    "    return training_data, inference_data, answer_tokens\n",
    "\n",
    "\n",
    "training_data, inference_data, answer_tokens = instruct_tokenization(\n",
    "    dataset_llm, tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from sklearn import metrics\n",
    "from functools import partial\n",
    "\n",
    "# TODO: make other metrics work\n",
    "hf_metrics = [\n",
    "    evaluate.load(\"accuracy\"),\n",
    "    # evaluate.load(\"f1\"),\n",
    "    # evaluate.load(\"precision\"),\n",
    "    # evaluate.load(\"recall\"),\n",
    "    # evaluate.load(\"confusion_matrix\"),\n",
    "]\n",
    "sklearn_metrics = {\n",
    "    # \"accuracy\": metrics.accuracy_score,\n",
    "    # \"balanced_accuracy\": metrics.balanced_accuracy_score,\n",
    "    # \"f1_weighted\": partial(metrics.f1_score, average=\"weighted\"),\n",
    "    # \"confusion_matrix\": metrics.confusion_matrix,\n",
    "}\n",
    "\n",
    "pred_slice_ids = [\n",
    "    (len(inference_ids), len(training_ids) - 1)\n",
    "    for inference_ids, training_ids in zip(\n",
    "        inference_data[\"test\"][\"input_ids\"], training_data[\"test\"][\"input_ids\"]\n",
    "    )\n",
    "]  # NOTE: the -1 accounts for the eos token, which is not present for the generation data\n",
    "\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple):\n",
    "        # Depending on the model and config, logits may contain extra tensors,\n",
    "        # like past_key_values, but logits always come first\n",
    "        logits = logits[0]\n",
    "    logits = logits[:, :, answer_tokens].argmax(dim=-1)\n",
    "\n",
    "    return torch.tensor(\n",
    "        answer_tokens,\n",
    "        device=\"cuda\",\n",
    "    )[logits]\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
    "    # by preprocess_logits_for_metrics but we need to shift the labels\n",
    "    preds = np.pad(preds, ((0, 0), (1, 0)), mode=\"constant\", constant_values=-100)\n",
    "    labels = np.pad(labels, ((0, 0), (0, 1)), mode=\"constant\", constant_values=-100)\n",
    "\n",
    "    def get_slice(y):\n",
    "        return [\n",
    "            [token for token, label_token in zip(row, label) if label_token != -100][\n",
    "                start_id:end_id\n",
    "            ]\n",
    "            for (start_id, end_id), row, label in zip(pred_slice_ids, y, labels)\n",
    "        ]\n",
    "\n",
    "    y_true = get_slice(labels)\n",
    "    y_pred = get_slice(preds)\n",
    "    # accuracy based on the first token of the vote\n",
    "    y_true = [row[0] for row in y_true]\n",
    "    y_pred = [row[0] for row in y_pred]\n",
    "\n",
    "    results = {}\n",
    "    for metric in hf_metrics:\n",
    "        results |= metric.compute(predictions=y_pred, references=y_true)\n",
    "    for metric_name, metric_func in sklearn_metrics.items():\n",
    "        results[metric_name] = metric_func(y_true=y_true, y_pred=y_pred)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/work/survai-finetuning/wandb/run-20241003_125716-8wpql7qg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobihol/survai-finetuning/runs/8wpql7qg' target=\"_blank\">unsloth/Llama-3.2-1B-Instruct_2024-10-03_12-57-16</a></strong> to <a href='https://wandb.ai/tobihol/survai-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobihol/survai-finetuning' target=\"_blank\">https://wandb.ai/tobihol/survai-finetuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobihol/survai-finetuning/runs/8wpql7qg' target=\"_blank\">https://wandb.ai/tobihol/survai-finetuning/runs/8wpql7qg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/survai-finetuning/.venv/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/jovyan/work/survai-finetuning/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/survai-finetuning/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262326</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.253618</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252551</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/survai-finetuning/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "/home/jovyan/work/survai-finetuning/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212a37d5a738463ab69797ac802c70e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.049 MB of 0.054 MB uploaded\\r'), FloatProgress(value=0.9085997775463004, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–ˆâ–†â–ƒ</td></tr><tr><td>eval/loss</td><td>â–†â–ˆâ–‚â–</td></tr><tr><td>eval/model_preparation_time</td><td>â–â–â–â–</td></tr><tr><td>eval/runtime</td><td>â–ˆâ–‚â–â–†</td></tr><tr><td>eval/samples_per_second</td><td>â–â–‡â–ˆâ–ƒ</td></tr><tr><td>eval/steps_per_second</td><td>â–â–‡â–ˆâ–ƒ</td></tr><tr><td>train/epoch</td><td>â–â–…â–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–ƒâ–†â–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.75</td></tr><tr><td>eval/loss</td><td>0.25255</td></tr><tr><td>eval/model_preparation_time</td><td>0.0036</td></tr><tr><td>eval/runtime</td><td>0.3445</td></tr><tr><td>eval/samples_per_second</td><td>58.052</td></tr><tr><td>eval/steps_per_second</td><td>8.708</td></tr><tr><td>total_flos</td><td>200564219805696.0</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>30</td></tr><tr><td>train_loss</td><td>0.22925</td></tr><tr><td>train_runtime</td><td>13.0166</td></tr><tr><td>train_samples_per_second</td><td>18.438</td></tr><tr><td>train_steps_per_second</td><td>2.305</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unsloth/Llama-3.2-1B-Instruct_2024-10-03_12-57-16</strong> at: <a href='https://wandb.ai/tobihol/survai-finetuning/runs/8wpql7qg' target=\"_blank\">https://wandb.ai/tobihol/survai-finetuning/runs/8wpql7qg</a><br/> View project at: <a href='https://wandb.ai/tobihol/survai-finetuning' target=\"_blank\">https://wandb.ai/tobihol/survai-finetuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241003_125716-8wpql7qg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "run_name = f'{model_id}_{now}'\n",
    "\n",
    "# wandb.init(\n",
    "#     mode='disabled',\n",
    "# )\n",
    "\n",
    "wandb.init(\n",
    "    project=\"survai-finetuning\",\n",
    "    name=run_name,\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=training_data[\"train\"].select(range(80)),\n",
    "    eval_dataset=training_data[\"test\"].select(range(20)),\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        gradient_checkpointing=True,\n",
    "        gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "        fp16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "\n",
    "        # train/eval settings\n",
    "        num_train_epochs=3,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "\n",
    "        # logging\n",
    "        report_to=\"wandb\",\n",
    "        run_name=\"test-run\",\n",
    "    ),\n",
    "    # tokenizer=tokenizer,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.evaluate()\n",
    "trainer.train()\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Extraction\n",
    "\n",
    "<!-- - https://arxiv.org/pdf/2307.09702, https://github.com/dottxt-ai/outlines -->\n",
    "Different modles for answer extraction:\n",
    "- https://blog.eleuther.ai/multiple-choice-normalization/\n",
    "- https://github.com/huggingface/lighteval\n",
    "\n",
    "Problems:\n",
    "- One token solutions:\n",
    "    - less compute intensive\n",
    "    - do not require normalisation\n",
    "    - only works if all first token are destinct\n",
    "- Multi token solutions:\n",
    "    - more compute intensive (muliplies by number of lables)\n",
    "    - some requires normalisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things we did not do\n",
    "\n",
    "- hyperparameter search\n",
    "- cross validation\n",
    "- running multiple seeds "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (survai-finetuning)",
   "language": "python",
   "name": "survai-finetuning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
